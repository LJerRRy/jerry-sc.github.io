---
layout: post
title: 软间隔支持向量机
date: 2016-12-08
author: Jerry
header-img: img/blue.png
catalog: true
tags:
- Machine Learning
---


### 问题引入
如果我们坚持分类器不能犯错误，那么训练得到的模型可能会产生过拟合的现象。那如果，我们允许模型犯少量错误，那会怎么样？

### 软间隔支持向量机
我们可以借用POCKET的方法，用违反的样例点**个数**惩罚目标函数。
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/1.png)

化简后有：
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/2.png)

然而，由于需要计数，导致该问题时一个NP-hard问题；此外该方法无法度量犯错的大小。因此引入 ***margin violation*** 概念。
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/3.png)

![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/4.png)

对于惩罚项，我们使用 margin violation 来代替 error count。使用此方法，原问题仍然是一个二次规划（QP）问题，因此我们仍然可以按照原来的方法计算。
C为权衡系数，如果C越大，越不能容忍错误；反之，亦然。
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/5.png)

### 对偶问题
与之前求对偶问题类似：
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/6.png)

![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/7.png)

![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/8.png)

![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/9.png)

### 核函数 软间隔 SVM
核函数软间隔SVM模型与核函数硬间隔类似，唯独在求解b的过程中不同。
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/10.png)

### 几何意义
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/11.png)

#### 关于调参，模型选择
对于软间隔SVM来说，需要调整的参数有gama，C。我们必须小心尝试选择。
通常，我们可以用cross validation 进行选择。此外，可以证明的是：
![enter image description here](http://7xt1xs.com1.z0.glb.clouddn.com/ml/soft_svm/12.png)

**交叉验证的错误率小于等于SV支持向量的数量与所有样本点数量的比值**。虽然，这个比值只是一个上限，但是这可以告诉我们这个模型可能比较危险，相当于为我们做了安全性检查（safety check）

### Reference
- 台大《机器学习》——林轩田